{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW6-8LTXQahk"
      },
      "source": [
        "# Tutorial 12 - Object Detection\n",
        "\n",
        "## Dr. David C. Schedl\n",
        "\n",
        "This tutorial is geared towards students **experienced in programming** and aims to introduce you to **Digital Imaging / Computer Vision** techniques.\n",
        "\n",
        "We will look at object detection with a very modern network architecture (DETR a Vision Transformer) and the HuggingFace API (HuggingFace's `transformers` building on PyTorch).\n",
        "\n",
        "For faster processing, it is recommended to use a **GPU**. In Google Colab go to the menu and select **Edit** -> **Notebook settings** -> **Hardware accelerator** -> switch to **GPU**.\n",
        "\n",
        "Useful links:\n",
        "* [DETR on HuggingFace](https://huggingface.co/facebook/detr-resnet-50)\n",
        "* [DETR on Github (by Facebook research)](https://github.com/facebookresearch/detr)\n",
        "* [PyTorch documentation](https://pytorch.org/docs/stable/index.html)\n",
        "\n",
        "\n",
        "##### Acknowledgements\n",
        "The code of this tutorial is based on the example code on [HuggingFace](https://huggingface.co/facebook/detr-resnet-50)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNY4vET3Qaho"
      },
      "source": [
        "We will work with images today. So let's download some with `curl`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzmQC4I3Qaho"
      },
      "outputs": [],
      "source": [
        "!mkdir \"data\"\n",
        "!curl -o \"./data/couch.jpg\" \"http://images.cocodataset.org/val2017/000000039769.jpg\" --silent\n",
        "!curl -o \"./data/teddy.jpg\" \"https://farm5.staticflickr.com/4100/4893226511_941ce57389_z.jpg\" --silent\n",
        "!curl -o \"./data/safari.jpg\" \"https://farm4.staticflickr.com/3380/3519870985_2d2b50338d_z.jpg\" --silent\n",
        "!curl -o \"./data/rider.jpg\" \"http://images.cocodataset.org/val2017/000000439715.jpg\" --silent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EfrFyxJQahp"
      },
      "source": [
        "## Initilization\n",
        "\n",
        "As always let's import useful libraries, first.\n",
        "HuggingFace transformers are not installed (per default) on Colab. So let's install some requirements with `pip install transformers timm` (if the import fails). \n",
        "If you get an error in the next cells, try to restart your runtime!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAFo6x6KQahp"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "except:\n",
        "  !pip install transformers timm # first install the HuggingFace transformers API\n",
        "  from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type != \"cuda\":\n",
        "    print(\"Using CPU! things will be slow! :(\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWYK8BF8Qahq"
      },
      "source": [
        "## Init the Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gfy04FFQahq"
      },
      "outputs": [],
      "source": [
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "class_names = model.config.id2label\n",
        "model.to(device)  # send model to GPU\n",
        "print(class_names)  # display what our detector can detect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4kzXl7vQahq"
      },
      "source": [
        "## Load the images\n",
        "\n",
        "Let's load some images and display them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YsNFcI9Qahr"
      },
      "outputs": [],
      "source": [
        "images = [\n",
        "    Image.open(f\"./data/{name}.jpg\") for name in [\"couch\", \"teddy\", \"rider\", \"safari\"]\n",
        "]\n",
        "\n",
        "# display images with matplotlib\n",
        "for image in images:\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "torch.cuda.empty_cache()  # free up GPU memory\n",
        "inputs = [processor(images=img, return_tensors=\"pt\") for img in images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddoYZZNYQahr"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for i, inp in enumerate(inputs):\n",
        "    torch.cuda.empty_cache()  # free up GPU memory\n",
        "    inp.to(device)  # send inputs to GPU\n",
        "\n",
        "    outputs = model(**inp)\n",
        "    # move outputs to CPU\n",
        "    for k in outputs.keys():\n",
        "        if outputs[k] is not None:\n",
        "            outputs[k] = outputs[k].to(\"cpu\")\n",
        "\n",
        "    # display the image\n",
        "    image = images[i]\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "    # convert outputs (bounding boxes and class logits) to COCO API\n",
        "    # let's only keep detections with score > 0.9\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = processor.post_process_object_detection(\n",
        "        outputs, target_sizes=target_sizes, threshold=0.9\n",
        "    )[0]\n",
        "\n",
        "    for score, label, box in zip(\n",
        "        results[\"scores\"], results[\"labels\"], results[\"boxes\"]\n",
        "    ):\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        print(\n",
        "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "            f\"{round(score.item(), 3)} at location {box}\"\n",
        "        )\n",
        "    predictions.append(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pDscUhI3ezz"
      },
      "source": [
        "### Exercise 01 üìù: Visualizing the bounding boxes. \n",
        "\n",
        "Draw the bounding boxes with labels and confidence scores on the images.\n",
        "\n",
        "You can use the `images` and `predictions` list (one element for each image) from above.\n",
        "One prediction is a dictionary with the following keys: `labels`, `scores`, `boxes`.\n",
        "Boxes are in the format `[x0, y0, x1, y1]` (top-left and bottom-right corner).\n",
        "\n",
        "You can use pyplot's `plot` and `text` functions to draw the boxes (and text) on the images.\n",
        "\n",
        "Optionally, you can also use the `cv2.rectangle` function to draw the boxes. Note that OpenCV draws in the image directly, so you don't need to return the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k4xMhcJ3ezz"
      },
      "outputs": [],
      "source": [
        "def visualize_detection(image, results):\n",
        "    for score, label, box in zip(\n",
        "        results[\"scores\"], results[\"labels\"], results[\"boxes\"]\n",
        "    ):\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        x1, y1, x2, y2 = box\n",
        "\n",
        "        # TODO: add predictions to images\n",
        "\n",
        "        # print(\n",
        "        #     f\"Detected {class_names[label.item()]} with confidence \"\n",
        "        #     f\"{round(score.item(), 3)} at location {box}\"\n",
        "        # )\n",
        "\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    plt.imshow(image)\n",
        "    visualize_detection(image, predictions[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo-FZ-h8Qahs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a05e4fa746b81761c76a645b508c0f51cdd970f4b4b50ae36c6a73f9a174174"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
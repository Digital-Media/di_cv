{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bk92nT2wT4U8"
      },
      "source": [
        "# Homework 04 - Image Classification\n",
        "\n",
        "Contact: David C. Schedl (david.schedl@fh-hagenberg.at)\n",
        "\n",
        "Note: this is the starter pack for the **Digital Imaging / Computer Vision** homework. You do not need to use the exact same template and can start from scratch as well!\n",
        "Using regular Python files (.py) is also possible."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GMb4sAogUarc"
      },
      "source": [
        "# Task \n",
        "<a name=\"Task-A\" id=\"Task-A\"> </a>\n",
        "\n",
        "The goal of this assignment is to familiarize yourself with deep learning for the task of image classification.\n",
        "You should pick a **dataset** of your choice and train multiple **classifiers** to distinguish between different classes of images. \n",
        "\n",
        "\n",
        "The different classifiers/techniques that you should try are:\n",
        " * *Optional: Linear Classifiers (to familiarize yourself with the concept),*\n",
        " * a simple Multi-Layer Perceptron (MLP) or NN,\n",
        " * a Convolutional Neural Network (CNN) such as LeNet,\n",
        " * a pretrained model (CNN or another architecture) with Transfer Learning (TL).\n",
        "\n",
        "The imagedataset is up to you. You can use a dataset from the [PyTorch vision datasets](https://pytorch.org/vision/stable/datasets.html) or any other dataset that you find interesting. In the course we already worked with MNIST and CIFAR10. \n",
        "\n",
        "Train those networks and compare the results. Optionally, you can also try to modify the architecture of the individual networks (e.g., the MLP) to improve the results.\n",
        "\n",
        "You can use PyTorch or TensorFlow for this assignment.\n",
        "\n",
        "\n",
        "**Hint(s):** \n",
        "- Start simple (e.g, use MNIST/CIFAR10 and a small network) and get more complicated if you are sure that everything works correctly.\n",
        "- For training try to get a fast system (e.g., with an NVIDIA GPU) or use Google Colab or Amazon SageMaker. *Note that Colab will kick you from their servers after you use too much RAM or CPU time.*\n",
        "- Plan enough time for this assignment. It can be quite time-consuming to train a network for a high-resolution dataset (start simple).\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Let's import useful libraries, first. \n",
        "We'll download binary images into the `binary_leaves` folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading a dataset\n",
        "\n",
        "Below you can find the code to load and display a dataset with PyTorch vision.\n",
        "\n",
        "We will use **E**MNIST as example. It is an extension of the MNIST dataset with 47 classes (digits and letters).\n",
        "If you want to simplify things use `split='mnist'` to only get the original MNIST (without the E) digits.\n",
        "\n",
        "If you want to use a dataset with higher resolution images you can use `transforms.Resize` to directly downscale the images while loading the dataset ([PyTorch transformations](https://pytorch.org/vision/stable/transforms.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose(\n",
        "        [\n",
        "            #transforms.Resize((32, 32)), <-- for large images\n",
        "            transforms.ToTensor(),\n",
        "        ]             ),\n",
        "    \"val\": transforms.Compose(\n",
        "        [\n",
        "            #transforms.Resize((32, 32)), <-- for large images\n",
        "            transforms.ToTensor(),\n",
        "        ]    ),\n",
        "}\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "image_datasets = {\n",
        "    \"train\": torchvision.datasets.EMNIST(\n",
        "        root=\"./data\", split=\"balanced\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=data_transforms[\"train\"],\n",
        "    ),\n",
        "    \"val\": torchvision.datasets.EMNIST(\n",
        "        root=\"./data\",\n",
        "        split=\"balanced\",\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=data_transforms[\"val\"],\n",
        "    ),\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(\n",
        "        image_datasets[x],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True if x == \"train\" else False,\n",
        "        num_workers=2,\n",
        "    )\n",
        "    for x in [\"train\", \"val\"]\n",
        "}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
        "class_names = image_datasets[\"train\"].classes\n",
        "print(\"number of classes: \", len(class_names))\n",
        "print(dataset_sizes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visualize some images from the (training) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize sample images of the training dataset \n",
        "def imshow(inp, title=None, ax=plt):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((2, 1, 0)) # move the color dimension to the last axis\n",
        "    # NOTE: for the EMNIST dataset we flip the x and y axis!!! (remove for other datasets)\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    ax.imshow(inp[:,:,0], cmap=\"gray\")\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders[\"train\"]))\n",
        "\n",
        "plt.figure()\n",
        "# Make a grid from batch\n",
        "for i in range(len(inputs)):\n",
        "    ax = plt.subplot(math.ceil(len(inputs)/8), 8, i + 1, xticks=[],\n",
        "                        yticks=[],)\n",
        "    imshow(inputs[i], title=class_names[classes[i]], ax=ax)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LeNet-5 in PyTorch\n",
        "\n",
        "Below you can find the code for a (modernized) LeNet-5 architecture in PyTorch. \n",
        "Inspired by [this](https://towardsdatascience.com/implementing-yann-lecuns-lenet-5-in-pytorch-5e05a0911320) blog post."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a model\n",
        "inputs, classes = next(iter(dataloaders[\"train\"]))\n",
        "input_shape = inputs[0].shape\n",
        "print(\"input:\", input_shape)\n",
        "nb_classes = len(class_names)\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape, nb_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_shape[0], 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2),)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(20, 50 , kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(input_shape[1]//4*input_shape[2]//4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, nb_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = CNNModel(input_shape, nb_classes) # instance the model\n",
        "print( \"output:\", model(inputs).shape ) # check the output shape of the model -> (batch_size, nb_classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU\n",
        "\n",
        "Running the code on the GPU is easy. Just move the model and the data to the GPU with `model.to(device)` and `data.to(device)`.\n",
        "You can check if you have a GPU available with `torch.cuda.is_available()`.\n",
        "\n",
        "When data is moved to the GPU it is stored on the GPU's memory. You cannot access it from the CPU anymore. Thus, you need to move it back to the CPU with `data.cpu()`.\n",
        "\n",
        "If you want to use a GPU in Colab, go to the menu and select **Edit** -> **Notebook settings** -> **Hardware accelerator** -> switch to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if you want to use a GPU (recommended) use `tensor.to(device)`\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type != \"cuda\":\n",
        "    print(\"Using CPU! things will be slow! :(\")\n",
        "\n",
        "model = model.to(device) # move the model to the GPU\n",
        "output = model(inputs.to(device)) # move the input to the GPU and run the model\n",
        "output = output.cpu() # move the output back to the CPU for further processing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further comments/hints:\n",
        "*   You do not need to come up with super efficient implementations or a perfect classifier! It is mostly about understanding the topic and the problem.\n",
        "*   Think about the options and parameters, train it, and evaluate your solutions on the test images.\n",
        "*   Summarize your findings and evaluations in the report! \n",
        "\n",
        "\n",
        "**Have fun!** ðŸ¤–\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Homework.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a05e4fa746b81761c76a645b508c0f51cdd970f4b4b50ae36c6a73f9a174174"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

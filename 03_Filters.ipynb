{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schedldave/cv2022/blob/main/03_Filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuUAgQFQlsJU"
      },
      "source": [
        "# Tutorial 03 - Filters\n",
        "\n",
        "## Dr. David C. Schedl\n",
        "\n",
        "Note: this tutorial is geared towards students **experienced in programming** and aims to introduce you to **Computer Vision** techniques.\n",
        "\n",
        "\n",
        "Useful links:\n",
        "* OpenCV Tutorials: https://docs.opencv.org/master/d9/df8/tutorial_root.html\n",
        "* Image Processing in Pyhton: https://github.com/xn2333/OpenCV/blob/master/Seminar_Image_Processing_in_Python.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVOsLEGclsJZ"
      },
      "source": [
        "# Contents\n",
        "\n",
        "This notebook covers topics such as Filters, Fourier Transformation and Interpolation\n",
        "\n",
        "Table of Contents  \n",
        "- [Filters in OpenCV](#Filters)\n",
        "    - Average Filter\n",
        "    - Gaussian Filter\n",
        "    - Border Handling\n",
        "- [Fourier Transformation](#Fourier_Spectrum)\n",
        "    - FFT of Images\n",
        "    - Inverse FFT\n",
        "    - Convolution Theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weMMc2WZlsJc"
      },
      "source": [
        "# Initilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkUzZ6lWK_S5"
      },
      "source": [
        "As always let's import useful libraries, first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpvh7PPVlsJg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 # openCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnGyZdM2LH71"
      },
      "source": [
        "We will work with images today. So let's download some with `curl` (the same sources as in `02_OpenCV.ipynb`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTgznuO-LMMH",
        "outputId": "f4e37d68-876a-43ba-f2b0-ebf1a3992e3a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!curl -o \"cat.jpg\" \"https://placekitten.com/256/256\"\n",
        "\n",
        "!curl -o \"gogh.jpg\" \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Vincent_van_Gogh_-_National_Gallery_of_Art.JPG/367px-Vincent_van_Gogh_-_National_Gallery_of_Art.JPG\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCkGf5jg0KRg"
      },
      "source": [
        "Let's define utility functions to display images, in Jupyter Notebooks. OpenCV's `imshow` does not work and matplotlib's `imshow` needs special treatment due to color channel handling (RGB vs. BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ANEHCv0a-9",
        "outputId": "6d51a780-a918-4e55-bc0f-a8933d34f1f6"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab')\n",
        "  from google.colab.patches import cv2_imshow\n",
        "else:\n",
        "  print('Not running on CoLab')\n",
        "  def cv2_imshow(img):\n",
        "      \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n",
        "\n",
        "        Args:\n",
        "          img : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
        "            (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n",
        "            image.\n",
        "      \"\"\"\n",
        "      cv2.imshow('image', img)\n",
        "      cv2.waitKey(0)\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "def imshow(image, *args, **kwargs):\n",
        "    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks using matplotlib.\n",
        "\n",
        "        Args:\n",
        "          image : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
        "            (N, M, 3) is an NxM BGR color image. \n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "      # Height, width, channels\n",
        "      # Assume BGR, do a conversion  \n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Draw the image\n",
        "    plt.imshow(image, *args, **kwargs)\n",
        "    # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
        "    plt.axis('off')\n",
        "    # Make sure it outputs\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1E5rZhL21bG"
      },
      "source": [
        "# Filters\n",
        "\n",
        "Image filters in OpenCV are applied with `cv2.filter2D(img,-1,kernel)`, where the image and the kernel are numpy arrays.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_uopOWR8Edv"
      },
      "source": [
        "## Average\n",
        "\n",
        "Let's start with a simple average filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "0f7tq2_D4Vy9",
        "outputId": "27a95e0b-4524-4238-9e8e-4cafdfadb4ff"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('cat.jpg')\n",
        "\n",
        "k = 5 # kernel size\n",
        "kernel = np.ones((k,k),np.float32)/(k**2)\n",
        "print(kernel)\n",
        "dst = cv2.filter2D(img,-1,kernel)\n",
        "\n",
        "plt.figure(figsize=(15,10)) # this command makes the figure larger so we see the filter results clearer\n",
        "plt.subplot(121),imshow(img),plt.title('Original')\n",
        "plt.subplot(122),imshow(dst),plt.title(r'Averaging ({}$\\times${})'.format(k,k))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgsQ9Q2A8HAw"
      },
      "source": [
        "## Gaussian Filter\n",
        "\n",
        "An average filter produces blocky or boxy results, that's why it is also called a box filter. A smoother result can be achieved with a Gaussian Kernel. \n",
        "OpenCV's `getGaussianKernel` function produces a one-dimensional seperable Gaussian kernel. To retrieve the 2D variant, we need to (matrix) multiply two 1D kernel.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "pVi5GtCs8JBW",
        "outputId": "6bb0b7d3-25fd-4b41-b0ec-a0fda9bd6473"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('cat.jpg')\n",
        "\n",
        "k = 5 # kernel size and sigma\n",
        "kernel = cv2.getGaussianKernel(k,-1)\n",
        "print(kernel.T)\n",
        "kernel = kernel @ kernel.T # compute 2D from seperable kernel\n",
        "print(kernel)\n",
        "dst = cv2.filter2D(img,-1,kernel)\n",
        "\n",
        "plt.figure(figsize=(20,15)) # make the figure larger\n",
        "plt.subplot(131),imshow(img),plt.title('Original')\n",
        "plt.subplot(132),imshow(kernel, cmap = 'gray'),plt.title('Kernel')\n",
        "plt.subplot(133),imshow(dst),plt.title(r'Filtered ({}$\\times${})'.format(k,k))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YazQWWkS2kDN"
      },
      "source": [
        "## Border handling\n",
        "\n",
        "Border handling especially for large kernels is important. OpenCV provides various options. Default is to reflect the image at the border. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "grtMJQ-9u39B",
        "outputId": "5550c895-bc1f-4cf2-f098-bd0a237a7329"
      },
      "outputs": [],
      "source": [
        "img = cv2.resize( cv2.imread('cat.jpg'), (10,10) )\n",
        "\n",
        "k = 7 # kernel size and sigma\n",
        "kernel = np.ones((k,k),np.float32)/(k**2)\n",
        "const   = cv2.filter2D(img, -1, kernel, borderType=cv2.BORDER_CONSTANT)   # 000000|abcdefgh|0000000\n",
        "reflect = cv2.filter2D(img, -1, kernel, borderType=cv2.BORDER_REFLECT)    # fedcba|abcdefgh|hgfedcb\n",
        "repeat  = cv2.filter2D(img, -1, kernel, borderType=cv2.BORDER_REPLICATE)  # aaaaaa|abcdefgh|hhhhhhh\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,10)) # make the figure larger\n",
        "plt.subplot(131),imshow(const),  plt.title(r'Constant border')\n",
        "plt.subplot(132),imshow(reflect),plt.title(r'Reflect border')\n",
        "plt.subplot(133),imshow(repeat), plt.title(r'Repeat border')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85mR3YUU3IMi"
      },
      "source": [
        "# Fourier Spectrum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhnXM1vfngqX"
      },
      "source": [
        "## Fourier Transformation of Images\n",
        "\n",
        "The numpy library provides a two-dimensional implementation of the Fast Fourier Transformation (FFT): `numpy.fft.fft2`. \n",
        "The resulting spectrum is an array with complex numbers, which are supported by numpy. \n",
        "We can visualize the spectrum by displaying it like a regular image. Since it is complex we will show only the magnitude (with `numpy.abs`) and we'll use a logarithmic scale. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "7pLXCoZ93QcV",
        "outputId": "7d3b93a4-7299-47eb-a1a6-956eeabdd9b7"
      },
      "outputs": [],
      "source": [
        "# Load an image and convert it to grayscale\n",
        "gray = cv2.cvtColor(cv2.imread('cat.jpg'), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Transform the image to frequency domain\n",
        "f = np.fft.fft2(gray)\n",
        "print(repr(f.dtype))\n",
        "# Bring the zero-frequency component to the center\n",
        "fshift = np.fft.fftshift(f)\n",
        "magnitude_spectrum = np.log(np.abs(fshift))\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(121), imshow(gray, cmap = 'gray'), plt.title('Input Image')\n",
        "plt.subplot(122), imshow(magnitude_spectrum, cmap = 'gray'), plt.title('Magnitude Spectrum')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2f2YFeknliT"
      },
      "source": [
        "## Inverse Fourier Transformation\n",
        "\n",
        "While the FFT transform a signal into its spectral domain, the inverse FFT (`numpy.fft.ifft2`) transforms a spectrum into the spatial domain. Note that the resulting array is complex again, where the complex part is zero (or close to zero). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "VscLxy-NX71h",
        "outputId": "12da6a5f-43a6-4d75-fae4-82fb8b0d1022"
      },
      "outputs": [],
      "source": [
        "# inverse fourier transform\n",
        "iff = np.fft.ifft2(f)\n",
        "print(iff.dtype)\n",
        "#print(repr(iff))\n",
        "\n",
        "plt.figure(figsize=(15,10)), imshow(np.abs(iff), cmap='gray'), plt.title('Inverse FFT')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzwgRUeCyQw2"
      },
      "source": [
        "Let's look at some artificial spectra and the corresponding signal. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "vl_XsILorcd4",
        "outputId": "7e1e88b1-42ba-4372-a4f3-7269137a881d"
      },
      "outputs": [],
      "source": [
        "F = np.zeros((32,32),dtype=np.complex128)\n",
        "F[0,0] = np.prod(F.shape) # DC component (mean)\n",
        "F10 = F.copy()\n",
        "F10[1,0] = 1.0\n",
        "f10 = np.fft.ifft2(F10)\n",
        "\n",
        "F20 = F.copy()\n",
        "F20[2,0] = 1.0\n",
        "f20 = np.fft.ifft2(F20)\n",
        "\n",
        "F03 = F.copy()\n",
        "F03[0,3] = 1.0\n",
        "f03 = np.fft.ifft2(F03)\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(131), imshow(np.abs(f10), cmap='gray'), plt.title('ifft of F [1,0]')\n",
        "plt.subplot(132), imshow(np.abs(f20), cmap='gray'), plt.title('ifft of F [2,0]')\n",
        "plt.subplot(133), imshow(np.abs(f03), cmap='gray'), plt.title('ifft of F [0,3]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-XFqLB6gA8E"
      },
      "source": [
        "## Modifications in the Fourier Spectrum\n",
        "\n",
        "Let's remove some frequencies by setting them to zero in the spectrum. By converting the spectrum back in the spatial domain (`ifft2`) we can look at the results in the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Q_HeGdyfX7zi",
        "outputId": "4d773287-cc42-4754-ddae-0722f6f1735b"
      },
      "outputs": [],
      "source": [
        "rows, cols = gray.shape\n",
        "crow, ccol = round(rows/2) , round(cols/2)\n",
        "\n",
        "# remove low frequencies with a rectangle size of 20\n",
        "fcopy = fshift.copy()\n",
        "fcopy[crow-10:crow+10, ccol-10:ccol+10] = 0\n",
        "f_ishift = np.fft.ifftshift(fcopy)\n",
        "img_hf = np.fft.ifft2(f_ishift)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(131), plt.title( 'High Frequencies')\n",
        "imshow(np.abs(img_hf), cmap='gray')\n",
        "\n",
        "# remove high frequencies\n",
        "fcopy = np.zeros_like(fshift)\n",
        "fcopy[crow-10:crow+10, ccol-10:ccol+10] = fshift[crow-10:crow+10, ccol-10:ccol+10]\n",
        "f_ishift = np.fft.ifftshift(fcopy)\n",
        "img_lf = np.fft.ifft2(f_ishift)\n",
        "plt.subplot(132), plt.title( 'Low Frequencies')\n",
        "imshow(np.abs(img_lf), cmap='gray')\n",
        "\n",
        "# sum the low and high frequencies (Note: it is important to avoid using abs)\n",
        "plt.subplot(133), plt.title( 'Low + High Frequencies')\n",
        "imshow(np.abs(img_lf+img_hf), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia1IvjeGAw6r"
      },
      "source": [
        "## Convolution Theorem\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_amb5Xy8H_HW"
      },
      "source": [
        "A convolution is a point-wise operation in the spectral domain. \n",
        "Let's try this with our images. \n",
        "For very large kernels OpenCV's filter function uses FFT to speed up computations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "-6vg3HMnBbHr",
        "outputId": "89a72e84-fb5c-4e60-a279-5cf9608772ae"
      },
      "outputs": [],
      "source": [
        "# Load an image and convert it to grayscale\n",
        "f = cv2.cvtColor(cv2.imread('cat.jpg'), cv2.COLOR_RGB2GRAY)\n",
        "# Transform the image to frequency domain\n",
        "F = np.fft.fft2(f)\n",
        "\n",
        "rows, cols = f.shape\n",
        "crow, ccol = round(rows/2) , round(cols/2)\n",
        "\n",
        "# create a kernel\n",
        "k_size = 5 # kernel size and sigma\n",
        "kh = int(np.floor(k_size/2.0))\n",
        "kernel = cv2.getGaussianKernel(k_size,-1) \n",
        "kernel = kernel @ kernel.T # compute 2D from seperable kernel\n",
        "k = np.zeros(f.shape)\n",
        "k[crow-kh-1:crow+kh, ccol-kh-1:ccol+kh] = kernel # extend the size of the kernel\n",
        "K = np.fft.fft2(k)\n",
        "\n",
        "# apply the convolution in the spatial domain\n",
        "d = cv2.filter2D(f,-1,k)\n",
        "\n",
        "# apply a multiplication in the frequency domain\n",
        "D = np.zeros_like(F)\n",
        "D = F * K\n",
        "D_back = np.fft.ifftshift(np.fft.ifft2(D))\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(121), imshow(np.abs(d), cmap='gray'), plt.title('$f * k$')\n",
        "plt.subplot(122), imshow(np.abs(D_back), cmap='gray'), plt.title(r'FT$^{-1}( F \\cdot K )$')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXV5YxS7lsU2"
      },
      "source": [
        "# Exercises (Try it yourself)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHyGmaqu9kTd"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "**Mean Filter:** Implement an average filter yourself. Do not use any OpenCV functions (i.e., `filter2D`).\n",
        "Hint: you can use loops or slicing.\n",
        "\n",
        "**(a)** Load the image `gogh.jpg` and apply a $3 \\times 3$ filter on the image. Ignore the border (remove 1 pixel at the border).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eApmF1iMtmZH"
      },
      "outputs": [],
      "source": [
        "# Setup Excercise 1\n",
        "\n",
        "image = cv2.imread(\"gogh.jpg\")\n",
        "k = 3 # filter size\n",
        "\n",
        "# use opencv for reference\n",
        "kernel = np.ones((k,k),np.float32)/(k**2)\n",
        "ref = cv2.filter2D(image,-1,kernel)\n",
        "ref = ref[1:-1,1:-1,:] # remove border\n",
        "\n",
        "def MSE(A,B):\n",
        "  \"\"\"compute the mean squared error (MSE) between numpy array A and B\n",
        "  \"\"\"\n",
        "  return ((A - B)**2).mean(axis=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "FZickyq-9n-9",
        "outputId": "ea4548bc-9b01-4a13-96c8-60063b220ca6"
      },
      "outputs": [],
      "source": [
        "# Solution (a)\n",
        "\n",
        "avg = np.zeros(image.shape,dtype=np.float32)\n",
        "\n",
        "# compute average\n",
        "# Todo!\n",
        "\n",
        "# remove border\n",
        "avg = np.round(avg[0:-2,0:-2,:]).astype(np.uint8)\n",
        "\n",
        "# display\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121), imshow(avg), plt.title('manual filter')\n",
        "plt.subplot(122), imshow(ref), plt.title('opencv filter')\n",
        "plt.show()\n",
        "\n",
        "# compute MSE\n",
        "print( f'MSE: {MSE(avg,ref)}' )\n",
        "\n",
        "# check if close to reference\n",
        "assert np.isclose(avg,ref).all() == True # if everything is implemented correctly this should not cause an error!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOFCWJj2T8MQ"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "**Demosaicing:** Image sensors have a Bayer filter on the sensor elements (pixels). So every 2nd pixel in even rows is red, every 2nd pixel in odd rows is blue, and every 2nd pixel in all rows contains green.\n",
        "The missing colors need to be [interpolated](https://medium.com/swlh/image-demosaicing-bilinear-interpolation-vs-high-quality-linear-interpolation-5fd2268c4c7a). \n",
        "\n",
        "We will do that with linear interpolation.\n",
        "Implement the interpolation by filtering with a *hat* function.\n",
        "Think about the shape of the discrete *hat* function and use it.\n",
        "\n",
        "\n",
        "\n",
        "**(a)** Interpolate the green color channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW4O5fiQ-U_t"
      },
      "outputs": [],
      "source": [
        "# Setup Exercise 2\n",
        "from matplotlib import colors\n",
        "\n",
        "# from 02_OpenCV.ipynb\n",
        "image = cv2.imread(\"gogh.jpg\")\n",
        "green_mask = np.zeros(shape=image.shape[0:2],dtype=bool)\n",
        "green_mask[0::2,1::2] = True\n",
        "green_mask[1::2,0::2] = True\n",
        "\n",
        "# construct a Bayer image:\n",
        "bayer = np.zeros(shape=image.shape[:2],dtype=image.dtype)\n",
        "# assing colors (BGR)\n",
        "bayer[:,:][green_mask] = image[:,:,1][green_mask] # Green\n",
        "\n",
        "# show a zoomed in portion\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121), imshow(image[:16,:16,2],norm=colors.Normalize(0,255),cmap='gray'), plt.title('original green')\n",
        "plt.subplot(122), imshow(bayer[:16,:16],norm=colors.Normalize(0,255),cmap='gray'), plt.title('green Bayer')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zX977oItfhg"
      },
      "outputs": [],
      "source": [
        "# Solution (a)\n",
        "# green channel\n",
        "\n",
        "#inter = ...\n",
        "\n",
        "# display:\n",
        "#plt.figure(figsize=(15,10))\n",
        "#plt.subplot(121), imshow(image[:100,:100,1],norm=colors.Normalize(0,255),cmap='gray'), plt.title('original green channel')\n",
        "#plt.subplot(122), imshow(inter[:100,:100].astype(np.uint8),norm=colors.Normalize(0,255),cmap='gray'), plt.title('interpolated')\n",
        "#plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tXV5YxS7lsU2"
      ],
      "include_colab_link": true,
      "name": "03_Filters.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "0bae4c9257a18836fb2e3dc2d0aeb6355625d596c4075009294ab101cd3e0d3c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

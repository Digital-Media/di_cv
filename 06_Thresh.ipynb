{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Tutorial 06 - Thresholding\n"," \n"," ## Dr. David C. Schedl\n","\n"," Note: this tutorial is geared towards students **experienced in programming** and aims to introduce you to **Digital Imaging / Computer Vision** techniques.\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Table of Contents\n","\n"," - Thresholding\n"," - Binary Image Regions and their Properties\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Initilization"]},{"cell_type":"markdown","metadata":{},"source":[" As always let's import useful libraries, first."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import cv2  # openCV\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import plotly.express as px"]},{"cell_type":"markdown","metadata":{},"source":[" We will work with images today. So let's download some with `curl` (the same sources as in `02_OpenCV.ipynb`)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!curl -o \"cat.jpg\" \"https://placekitten.com/320/320\" --silent\n","!curl -o \"gogh.jpg\" \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Vincent_van_Gogh_-_National_Gallery_of_Art.JPG/367px-Vincent_van_Gogh_-_National_Gallery_of_Art.JPG\" --silent\n","!curl -o \"einstein.jpg\" \"https://www.cns.nyu.edu/~lcv/ssim/index_files/image003.jpg\" --silent\n","!curl -o \"woman.jpg\" \"https://live.staticflickr.com/8859/18045025168_3a1ffa6521_c_d.jpg\" --silent\n","!curl -o \"road110.png\" \"https://storage.googleapis.com/kagglesdsdata/datasets/671172/1181356/images/road110.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221024%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221024T141558Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4caf2429c7705e2a061941aece256a66296c5b4f7e28e427dcffd05d7eb720665a5619bfb139010c194fa31152f18d0dcc02b6aec87f4e19c614f726b9869acd9e6c2e3c716336ab6fd17dabdccd85d5fd832b2e1b5b46c241994d033ba340d4c5e7e4179903b78efa67ee9a8837606f6971612fc69acb2380f2c28aabeeb0ae0721c89c5dbf3cc0348bb5c3752c2ad8c341d61f8e3de78e8bf61a68e325024caf13b3ed2fc3957aa882fbe3029d2bb8c8d45bbb607043ec1f3594ad18a1de3795cc3577abc78c27957a15edeedba0c3eb9232d9252e686bdf04376aec8e34da7f074ee3d39bab6e8064bd0f007dfed69661bff1bc49a8019e0a9b2e0ff14344\"\n","!curl -o \"sudoku.png\" \"https://raw.githubusercontent.com/opencv/opencv/4.x/samples/data/sudoku.png\" --silent"]},{"cell_type":"markdown","metadata":{},"source":[" # Thresholding"]},{"cell_type":"markdown","metadata":{},"source":[" Let's first look at our sample image showing multiple coins on a fairly uniform background."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from skimage import data\n","\n","coins = data.coins()\n","\n","fig = plt.figure(figsize=(12, 7), facecolor=\"white\")\n","plt.subplot(1, 2, 1), plt.imshow(coins, cmap=\"gray\")\n","plt.title(f\"Image {coins.shape[::-1]}\"), plt.xticks([]), plt.yticks([])\n","plt.subplot(1, 2, 2), plt.hist(coins.ravel(), bins=256, range=[0, 255])\n","plt.title(\"Histogram\"), plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[" ## Global Thresholding\n","\n"," Let's first look at a global thresholding approach.\n"," All pixels with a value above the threshold are True, all pixels with a value below the threshold are False.\n"," Can you come up with a threshold value that separates the coins from the background? <br>\n"," You can also try to blur the image. Does this help?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a slider for changing the threshold\n","import matplotlib.pyplot as plt\n","from ipywidgets import interact, fixed, IntSlider, FloatSlider\n","from skimage import data\n","\n","img = data.coins()\n","print(img.shape)\n","\n","\n","def plot_threshold(threshold, blur=0):\n","    _img = img.copy()\n","\n","    if blur > 0:\n","        _img = cv2.GaussianBlur(_img, None, blur)\n","\n","    T = _img > threshold\n","\n","    # plot the thresholded image and the histogram\n","    fig = plt.figure(figsize=(15, 7))\n","    plt.subplot(1, 2, 1), plt.imshow(T, cmap=\"gray\", vmin=0, vmax=1)\n","    plt.title(f\"Threshold ({T.sum()/T.size*100:3.2f}% pixels selected)\"), plt.xticks(\n","        []\n","    ), plt.yticks([])\n","    plt.subplot(1, 2, 2),\n","    plt.hist(_img[T].ravel(), range=[0, 255], bins=256),\n","    plt.hist(_img[np.invert(T)].ravel(), range=[0, 255], bins=256)\n","    plt.show()\n","    # return fig\n","\n","\n","interact(\n","    plot_threshold,\n","    threshold=IntSlider(min=0, max=255, step=1, value=128),\n","    blur=FloatSlider(min=0, max=5, step=0.1, value=0),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Automatic Thresholding (Otsu)\n","\n","Let's now look at an automatic thresholding approach, where $q$ is computed based on some heuristics.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2 as cv\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","img = data.coins()\n","\n","# Otsu's thresholding\n","ret, th = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n","th = th > 0 \n","\n","# plot the thresholded image and the histogram\n","fig = plt.figure(figsize=(15, 7), facecolor=\"white\")\n","plt.subplot(1, 2, 1), plt.imshow(th, cmap=\"gray\", vmin=0, vmax=1)\n","plt.title(f\"Automatic Threshold at {ret} ({th.sum()/th.size*100:3.2f}% pixels selected)\"), plt.xticks(\n","    []\n","), plt.yticks([])\n","plt.subplot(1, 2, 2),\n","plt.hist(img[th].ravel(), range=[0, 255], bins=256),\n","plt.hist(img[np.invert(th)].ravel(), range=[0, 255], bins=256)\n","plt.show()\n","# return fig\n"]},{"cell_type":"markdown","metadata":{},"source":["### Exercise 1 üìù: <a name=\"Exercise_1\" id=\"Exercise_1\">  </a> Otsu under the hood \n","\n","The Otsu algorithm is based on the following idea: <br>\n","Given a grayscale image $I$ and a threshold $q$, we can compute the **weighted between-class variance** $B(q)$ as follows:\n","\n","$$\n","B(q) = c_{w} \\cdot \\sigma^2_{w}(q) + c_{b} \\cdot \\sigma^2_{b}(q)\n","$$\n","\n","where $\\sigma^2_{w}(q)$ is the variance of the **foreground** and $\\sigma^2_{b}(q)$ is the variance of the **background** and $c_{w}$ and $c_{b}$ are the number of pixels in the **foreground** and **background**, respectively.\n","\n","The **foreground** is defined as all pixels with a value greater than $q$ and the **background** as all pixels with a value less than and equal $q$. <br>\n","\n","The Otsu algorithm seeks to find the threshold $q$ that minimizes the **weighted between-class variance** $B(q)$.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img = data.coins()\n","#img = cv2.imread(\"cat.jpg\", 0)\n","#img = cv2.imread(\"gogh.jpg\", 0)\n","\n","# OpenCV's adaptive thresholding for reference\n","ref, _ = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n","\n","# calculate the global otsu threshold\n","def my_otsu(img):\n","    fn_min = np.inf\n","    thresh = -1\n","\n","    for i in range (256):\n","\n","        # apply threshold\n","        th = img > i\n","\n","        # count pixels in lower and upper half\n","        q1 = th.sum()\n","        q2 = np.invert(th).sum()\n","        if q1 < 1 or q2 < 1:\n","            # we want at least one pixel in each class\n","            continue\n","\n","        # calculate variances\n","        v1 = img[th].var()\n","        v2 = img[np.invert(th)].var()\n","\n","        # calculate the minimization function\n","        fn = q1 * v1 + q2 * v2\n","\n","        # check if this is a new minimum and save the threshold if so\n","        if fn < fn_min:\n","            fn_min = fn\n","            thresh = i\n","    return thresh\n","\n","print( f'Our Otsu threshold {my_otsu(img)} vs OpenCV\\'s {ref}')"]},{"cell_type":"markdown","metadata":{},"source":[" ## Local Thresholding\n","\n"," Let's now look at a local thresholding approach.\n"," In comparison to the global thresholding, the local thresholding is applied to small regions of the image.\n"," The region size is defined by the $w$ parameter."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2 as cv\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from skimage import data\n","\n","\n","def adaptive_threshold(w=11, c=2, blur=0):\n","    img = data.coins()\n","\n","    if blur > 0:\n","        img = cv2.GaussianBlur(img, None, blur)\n","\n","    th = cv.adaptiveThreshold(\n","        img, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, w, c\n","    )\n","\n","    fig = plt.figure(figsize=(15, 7), facecolor=\"white\")\n","    titles = [\n","        \"Original Image\" if blur == 0 else f\"Blurred Image\",\n","        \"Adaptive Mean Thresholding\",\n","    ]\n","    images = [img, th]\n","    for i in range(len(images)):\n","        plt.subplot(1, 2, i + 1), plt.imshow(images[i], \"gray\")\n","        plt.title(titles[i])\n","        plt.xticks([]), plt.yticks([])\n","    plt.show()\n","\n","\n","interact(\n","    adaptive_threshold,\n","    w=IntSlider(min=3, max=255, step=2, value=51),\n","    c=IntSlider(min=-50, max=50, step=1, value=2),\n","    blur=FloatSlider(min=0, max=5, step=0.1, value=0),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Another example: The Sudoko image\n","\n","Let's now look at another hard complex image: the Sudoko image (from the slides)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2 as cv\n","import numpy as np\n","from matplotlib import pyplot as plt\n","_img = cv.imread('sudoku.png',0)\n","img = cv.medianBlur(_img.copy(),7).copy()\n","ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n","th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n","            cv.THRESH_BINARY,11,2)\n","titles = ['Original Image', 'Global Thresholding ($q$ = 127)',\n","            'Adaptive Mean Thresholding']\n","images = [_img, th1, th2]\n","plt.figure(figsize=(15, 15), facecolor=\"white\")\n","for i in range(len(images)):\n","    plt.subplot(1,len(images),i+1),\n","    plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# manual local thresholding\n","\n","img = _img.copy()\n","thresh = np.zeros_like(img)\n","w = 51 # window size (square)\n","w_2 = w//2\n","for u in range(img.shape[0]):\n","    for v in range(img.shape[1]):\n","        uidx = np.clip(range(u-w_2, u+w_2+1), 0, img.shape[0]-1)\n","        vidx = np.clip(range(v-w_2, v+w_2+1), 0, img.shape[1]-1)\n","\n","        q = img[uidx, :][:,vidx].mean()\n","\n","        thresh[u,v] = img[u,v] > q\n","\n","\n","plt.imshow(thresh, cmap=\"gray\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Image Regions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# good settings for 'coins'\n","w = 115\n","c = -22\n","blur = 3\n","\n","img = data.coins()\n","img = cv2.GaussianBlur(img, None, blur)\n","\n","th = cv.adaptiveThreshold(\n","    img, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, w, c\n",")\n","binary = th > 0 \n","plt.imshow(binary, cmap=\"gray\", vmin=0, vmax=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# image regions\n","\n","import cv2\n","\n","# get binary regions of binary image and compute their properties (area, BBs, centroid)\n","retval, labels, stats, centroids = cv2.connectedComponentsWithStats(binary.astype(np.uint8))\n","print( f\"Found {len(np.unique(labels))-1} (connected) regions\")\n","\n","# compute the contour perimeter of each region\n","perimeters = np.zeros_like(stats[:,4])\n","for i in range(1, len(np.unique(labels))):\n","    perimeters[i] = cv2.arcLength(cv2.findContours((labels==i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0], True)\n","\n","plt.figure(figsize=(15, 7))\n","plt.imshow(labels, cmap=\"jet\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# for each label (except the background) plot the bounding box and centroid\n","\n","img = data.coins()\n","plt.figure(figsize=(15, 7))\n","plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n","\n","for i in range(1, len(stats)):\n","    x, y, w, h, area = stats[i]\n","    # plot the BB as rectangle\n","    plt.plot([x, x + w, x + w, x, x], [y, y, y + h, y + h, y], \"go-\")\n","    plt.plot(centroids[i, 0], centroids[i, 1], \"b+\")\n","    plt.text( x, y, f\"#: {i} \\nP: {perimeters[i]} \\nA: {area}\", color=\"black\", fontsize=10, verticalalignment=\"top\", horizontalalignment=\"left\")\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# contour area\n","\n","import cv2\n","\n","# get binary regions of binary\n","retval, labels, stats, centroids = cv2.connectedComponentsWithStats(binary.astype(np.uint8))\n","print(np.unique(labels))\n","\n","plt.figure(figsize=(15, 7))\n","plt.imshow(labels, cmap=\"jet\")\n","\n","\n","cv2.moments((labels==3).astype(np.uint8))"]},{"cell_type":"markdown","metadata":{},"source":["# Binary Image Regions: 5 shapes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load the shapes image and binarize it\n","img = cv2.imread(\"shapes.png\", cv2.IMREAD_GRAYSCALE)\n","# img = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n","img = (img>0).astype(np.uint8)\n","\n","# get binary regions of binary image and compute their properties (area, BBs, centroid)\n","retval, labels, stats, centroids = cv2.connectedComponentsWithStats(img)\n","print( f\"Found {len(np.unique(labels))-1} (connected) regions\")\n","\n","# compute the contour perimeter of each region\n","perimeters, circularities = np.zeros_like(stats[:,4]), np.zeros(stats[:,4].shape)\n","for i in range(1, len(np.unique(labels))):\n","    perimeters[i] = cv2.arcLength(cv2.findContours((labels==i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0], True)\n","    circularities[i] = 4.0*np.pi*stats[i,4].astype(float)/ (.95*perimeters[i].astype(float))**2\n","\n","\n","plt.figure(figsize=(15, 7), facecolor=\"white\")\n","plt.imshow(labels, cmap=\"tab10\", vmin=0, vmax=len(stats))\n","# turn off the axis\n","plt.axis(\"off\")\n","\n","for i in range(1, len(stats)):\n","    x, y, w, h, area = stats[i]\n","    # plot the BB as rectangle\n","    #plt.plot([x, x + w, x + w, x, x], [y, y, y + h, y + h, y], \"wo-\")\n","    plt.plot(centroids[i, 0], centroids[i, 1], \"k+\")\n","    plt.text( centroids[i, 0], y+h+10, f\"#: {i} \\n$P$: {perimeters[i]} \\n$A$: {area} \\n$C$: {circularities[i]:.2f}\", color=\"black\", fontsize=12,\n","        verticalalignment=\"top\", horizontalalignment=\"center\", # turn on latex rendering \n","    )\n","\n","\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# make a pandas table with the hu moments\n","import pandas as pd\n","pd.options.display.float_format = \"{:.2f}\".format\n","df = pd.DataFrame(columns= ['Property'] + [f\"Region_{i}\" for i in range(1, len(stats))])\n","\n","show_hu_log = True\n","\n","for i in range(1, len(stats)):\n","    m = cv2.moments((labels==i).astype(np.uint8), False)\n","    hu = cv2.HuMoments(m)\n","    if show_hu_log:\n","        df[f\"Region_{i}\"] = np.sign(hu.T[0]) * np.log(np.abs(hu.T[0]))\n","    else:\n","        df[f\"Region_{i}\"] = hu.T[0]\n","\n","if show_hu_log:\n","    df[\"Property\"] = [f\"log(œÜ{i+1})\" for i in range(7)]\n","else:\n","    df[\"Property\"] = [f\"œÜ{i+1}\" for i in range(7)]\n","\n","# add area, perimeter and circularity and place them as top rows\n","df.loc[-2] = [\"Area\"] + np.array(list(stats[1:,4])).astype(int).tolist()\n","df.loc[-3] = [\"Perimeter\"] + np.array(list(perimeters[1:])).astype(int).tolist()\n","df.loc[-1] = [\"Circularity\"] + list(circularities[1:])\n","\n","# sort by index\n","df.sort_index(inplace=True)\n","\n","# show the table\n","df"]},{"cell_type":"markdown","metadata":{},"source":["# some tests below (remove later)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import Video\n","\n","Video(r\"Dillon_Predator.mp4\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.datasets import mnist\n","from matplotlib import pyplot\n"," \n","#loading\n","(train_X, train_y), (test_X, test_y) = mnist.load_data()\n"," \n","#shape of dataset\n","print('X_train: ' + str(train_X.shape))\n","print('Y_train: ' + str(train_y.shape))\n","print('X_test:  '  + str(test_X.shape))\n","print('Y_test:  '  + str(test_y.shape))\n"," \n","#plotting\n","from matplotlib import pyplot\n","for i in range(9):  \n","    pyplot.subplot(330 + 1 + i)\n","    pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n","    pyplot.title(train_y[i])\n","    #print(train_X[i])\n","pyplot.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.datasets import load_digits\n","\n","digits = load_digits(n_class=6)\n","train_X, train_y = digits.data, digits.target\n","train_X = train_X.reshape((1083 ,8,8))\n","\n","#shape of dataset\n","print('X_train: ' + str(train_X.shape))\n","print('Y_train: ' + str(train_y.shape))\n"," \n","#plotting\n","from matplotlib import pyplot\n","for i in range(9):  \n","    pyplot.subplot(330 + 1 + i)\n","    pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n","    pyplot.title(train_y[i])\n","    #print(train_X[i])\n","pyplot.show()\n","print(train_X[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.manifold import TSNE\n","\n","# compute Hu moments for each image\n","hu_moments = []\n","for i in range(len(train_X)):\n","    hu_moments.append(cv2.HuMoments(cv2.moments((train_X[i]>0.001).astype(np.uint8))).flatten())\n","\n","# convert to numpy array\n","hu_moments = np.array(hu_moments)\n","print(hu_moments.shape)\n","\n","X_embedded = TSNE(\n","        learning_rate=\"auto\",\n","        n_iter=500,\n","        n_iter_without_progress=150,\n","        n_jobs=2,\n","        random_state=0,\n","    ).fit_transform(train_X.reshape((-1,64)), train_y)\n","X_embedded.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# calculate a centroid for each class\n","centroids = []\n","\n","for i in range(len(np.unique(train_y))):\n","    centroids.append(np.mean(hu_moments[train_y == i], axis=0))\n","\n","centroids = np.array(centroids)\n","print(centroids)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot the embedded data\n","plt.figure(figsize=(10, 10))\n","for i in range(len(np.unique(train_y))):\n","    idx = train_y == i\n","    plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], cmap=\"tab10\")\n","plt.legend( [f'{i}' for i in range(10)], loc='upper right', fontsize=20)"]},{"cell_type":"markdown","metadata":{},"source":["## Leaves "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","leaves = {\n","    'Japanese maple': range(1268,1323+1),\n","    #'Chinese cinnamon': range(1497,1551+1),\n","    'ginkgo, maidenhair tree': range(2424,2485+1),\n","    #'Chinese tulip tree': range(3511,3563+1),\n","    'tangerine': range(3566,3621+1),\n","}\n","\n","# load the leaves from ./data/flavia_leaves/Leaves\n","train_X, train_y = [], []\n","idx_to_label = {}\n","for i, (name, fileIds) in enumerate(leaves.items()):\n","    for fid in fileIds:\n","        img = cv2.imread(f\"./data/flavia_leaves/Leaves/{fid}.jpg\", cv2.IMREAD_GRAYSCALE)\n","        # resize images to 128x128\n","        # compute new size to keep aspect ratio\n","        h, w = img.shape\n","        new_h = 128\n","        new_w = int(w*128//h)\n","        \n","        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n","        binary = (img<254).astype(np.uint8)\n","        # find the regions and use the largest one\n","        retval, labels, stats, centroids = cv2.connectedComponentsWithStats(binary.astype(np.uint8))\n","        # find the largest region\n","        largest_region_id = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n","\n","\n","        binary = (labels == largest_region_id).astype(np.uint8)\n","        \n","        train_X.append(binary)\n","        train_y.append(i)\n","        # rotate the image by 90 degrees\n","        # for _ in range(4):\n","        #     train_X.append(img)\n","        #     train_y.append(i)\n","        #     # scale the image by 0.7\n","        #     _img = cv2.resize(img, (0,0), fx=0.7, fy=0.7)\n","        #     train_X.append(_img)\n","        #     train_y.append(i)\n","        #\n","        #    img = np.rot90(img)\n","    idx_to_label[i] = name\n","\n","train_X = np.array(train_X)\n","train_y = np.array(train_y)\n","\n","print(f\"Loaded {len(train_X)} images\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.histogram(train_y, bins=range(len(leaves)+1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","# display the first 10 images\n","plt.figure(figsize=(10, 10))\n","for i in range(len(idx_to_label)):\n","    plt.subplot(1, len(idx_to_label), i+1)\n","    # randomly select an image from the class\n","\n","    idx = np.random.choice(np.where(train_y == i)[0])\n","    binary = train_X[idx].copy()\n","    # # find the boundaries of the leaf\n","    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_NONE )\n","    assert len(contours) == 1\n","    contour = contours[0]\n","    # get the contour length\n","    contour_lengths = cv2.arcLength(contour, True)\n","    #print(contour_lengths)\n","    # compute eccentricity\n","    eccentricities = cv2.fitEllipse(contour)[1][0]/cv2.fitEllipse(contour)[1][1]\n","    #print(eccentricities)\n","    # compute area to perimeter ratio\n","    areas = cv2.contourArea(contour)\n","    #print(areas)\n","    # compute solidity\n","    circularity = 4*np.pi*areas/(contour_lengths**2)\n","    #print(solidity)\n"," \n","    # #draw the contour\n","    plt.imshow(binary, cmap=\"gray\")\n","    # convert to color\n","    cimg = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n","    binary = cv2.drawContours(cimg, contours, -1, (255,0,255), thickness=2)\n","    plt.imshow(cimg, cmap=\"gray\")\n","\n","    plt.title(f\"{idx_to_label[train_y[idx]][:10]} {circularity:.3f}\")\n","    plt.xticks([]), plt.yticks([])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.manifold import TSNE\n","\n","# compute Hu moments for each image\n","hu_moments = []\n","for i in range(len(train_X)):\n","    hu_moments.append(cv2.HuMoments(cv2.moments(train_X[i])).flatten())\n","\n","# compute circularity for each image\n","circularities = []\n","for i in range(len(train_X)):\n","    # find the boundaries of the leaf\n","    contours, _ = cv2.findContours(train_X[i], cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_NONE )\n","    assert len(contours) == 1\n","    contour = contours[0]\n","    # get the contour length\n","    contour_length = cv2.arcLength(contour, True)\n","    # compute area to perimeter ratio\n","    area = cv2.contourArea(contour)\n","    # compute solidity\n","    circularity = 4*np.pi*area/(contour_length**2)\n","    circularities.append(circularity)\n","\n","# convert to numpy array\n","hu_moments = np.array(hu_moments)\n","print(hu_moments.shape)\n","\n","X_embedded = TSNE(\n","        learning_rate=\"auto\",\n","        n_iter=500,\n","        n_iter_without_progress=150,\n","        n_jobs=2,\n","        random_state=0,\n","        init=\"pca\",\n","        perplexity=10,\n","    ).fit_transform(hu_moments[:,:], train_y)\n","X_embedded.shape\n","#print(X_embedded)\n","\n","# plot the embedded data\n","plt.figure(figsize=(10, 10))\n","for i in range(len(np.unique(train_y))):\n","    idx = train_y == i\n","    plt.scatter(X_embedded[idx, 0], X_embedded[idx, 1], cmap=\"tab10\")\n","plt.legend( [f'{idx_to_label[i]}' for i in range(len(idx_to_label))], loc='upper right', fontsize=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot the hu_moment data (only the first two moments)\n","plt.figure(figsize=(10, 10))\n","for i in range(len(np.unique(train_y))):\n","    idx = train_y == i\n","    plt.scatter(hu_moments[idx, 0], hu_moments[idx, 1], cmap=\"tab10\")\n","plt.legend( [f'{idx_to_label[i]}' for i in range(len(idx_to_label))], loc='upper right', fontsize=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(np.array(circularities).shape)\n","print(train_y.shape)\n","circularities = np.array(circularities)\n","circularities[train_y==i]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# calculate a centroid for each class\n","centroids = []\n","\n","for i in range(len(np.unique(train_y))):\n","    centroids.append(np.mean(hu_moments[train_y == i], axis=0))\n","\n","centroids = np.array(centroids)\n","print(centroids.shape)\n","\n","# compute the circularity centroid for each class\n","circularity_centroids = []\n","for i in range(len(np.unique(train_y))):\n","    circularity_centroids.append(np.mean(circularities[train_y == i], axis=0))\n","\n","\n","# print them in a table with the class name\n","for i in range(len(centroids)):\n","    print(f\"{idx_to_label[i][:5]} \" + \" \".join([f\"{c: .3e}\" for c in centroids[i]]) + f\" {circularity_centroids[i]:.3f}\")\n","\n","# plot the centroids of each class\n","plt.figure(figsize=(20, 10))\n","for i in range(7): \n","    plt.subplot(1, 8, i+1)\n","    plt.scatter(np.zeros_like(centroids[:,i]), centroids[:,i], c=range(len(idx_to_label)), cmap=\"tab10\")\n","    plt.scatter(range(10, len(hu_moments[:,i])+10), hu_moments[:,i], c=train_y, cmap=\"tab10\", alpha=0.1)\n","    #plt.xticks([]), plt.yticks([])\n","    plt.title(f\"Hu moment {i+1}\")\n","    \n","    for ii in range(len(idx_to_label)):\n","            plt.text(0, centroids[ii,i], idx_to_label[ii], fontsize=10)\n","\n","\n","\n","\n","circularity_centroids = np.array(circularity_centroids)\n","\n","# plot the circularity centroid of each class\n","plt.subplot(1, 8, 8)\n","\n","plt.scatter(np.zeros_like(circularity_centroids), circularity_centroids, c=range(len(idx_to_label)), cmap=\"tab10\")\n","plt.scatter(range(10, len(circularities)+10), circularities, c=train_y, cmap=\"tab10\", alpha=0.1)    \n","plt.xticks([]), plt.yticks([])\n","plt.title(f\"Circularity centroid\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0a05e4fa746b81761c76a645b508c0f51cdd970f4b4b50ae36c6a73f9a174174"}}},"nbformat":4,"nbformat_minor":2}

{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Tutorial 06 - Thresholding\n"," \n"," ## Dr. David C. Schedl\n","\n"," Note: this tutorial is geared towards students **experienced in programming** and aims to introduce you to **Digital Imaging / Computer Vision** techniques.\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Table of Contents\n","\n"," - Thresholding\n"," - Binary Image Regions and their Properties\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Initilization"]},{"cell_type":"markdown","metadata":{},"source":[" As always let's import useful libraries, first."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import cv2  # openCV\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","from ipywidgets import interact, fixed, IntSlider, FloatSlider\n","from skimage import data\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":[" We will work with images today. So let's download some with `curl` (the same sources as in `02_OpenCV.ipynb`)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!curl -o \"cat.jpg\" \"https://placekitten.com/320/320\" --silent\n","!curl -o \"gogh.jpg\" \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Vincent_van_Gogh_-_National_Gallery_of_Art.JPG/367px-Vincent_van_Gogh_-_National_Gallery_of_Art.JPG\" --silent\n","!curl -o \"sudoku.png\" \"https://raw.githubusercontent.com/opencv/opencv/4.x/samples/data/sudoku.png\" --silent\n","!curl -o \"shapes.png\" \"https://raw.githubusercontent.com/Digital-Media/di_cv/main/data/shapes.png\" --silent"]},{"cell_type":"markdown","metadata":{},"source":[" # Thresholding"]},{"cell_type":"markdown","metadata":{},"source":[" Let's first look at our sample image showing multiple coins on a fairly uniform background."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coins = data.coins()\n","\n","fig = plt.figure(figsize=(12, 7), facecolor=\"white\")\n","plt.subplot(1, 2, 1), plt.imshow(coins, cmap=\"gray\")\n","plt.title(f\"Image {coins.shape[::-1]}\"), plt.xticks([]), plt.yticks([])\n","plt.subplot(1, 2, 2), plt.hist(coins.ravel(), bins=256, range=[0, 255])\n","plt.title(\"Histogram\"), plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[" ## Global Thresholding\n","\n"," Let's first look at a global thresholding approach.\n"," All pixels with a value above the threshold are True, all pixels with a value below the threshold are False.\n"," Can you come up with a threshold value that separates the coins from the background? <br>\n"," You can also try to blur the image. Does this help?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a slider for changing the threshold\n","\n","img = data.coins()\n","print(img.shape)\n","\n","\n","def plot_threshold(threshold, blur=0):\n","    _img = img.copy()\n","\n","    if blur > 0:\n","        _img = cv2.GaussianBlur(_img, None, blur)\n","\n","    T = _img > threshold\n","\n","    # plot the thresholded image and the histogram\n","    fig = plt.figure(figsize=(15, 7))\n","    plt.subplot(1, 2, 1), plt.imshow(T, cmap=\"gray\", vmin=0, vmax=1)\n","    plt.title(f\"Threshold ({T.sum()/T.size*100:3.2f}% pixels selected)\"), plt.xticks(\n","        []\n","    ), plt.yticks([])\n","    plt.subplot(1, 2, 2),\n","    plt.hist(_img[T].ravel(), range=[0, 255], bins=256),\n","    plt.hist(_img[np.invert(T)].ravel(), range=[0, 255], bins=256)\n","    plt.show()\n","    # return fig\n","\n","\n","interact(\n","    plot_threshold,\n","    threshold=IntSlider(min=0, max=255, step=1, value=128),\n","    blur=FloatSlider(min=0, max=5, step=0.1, value=0),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Automatic Thresholding (Otsu)\n","\n","Let's now look at an automatic thresholding approach, where $q$ is computed based on some heuristics.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img = data.coins()\n","\n","# Otsu's thresholding\n","ret, th = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","th = th > 0 \n","\n","# plot the thresholded image and the histogram\n","fig = plt.figure(figsize=(15, 7), facecolor=\"white\")\n","plt.subplot(1, 2, 1), plt.imshow(th, cmap=\"gray\", vmin=0, vmax=1)\n","plt.title(f\"Automatic Threshold at {ret} ({th.sum()/th.size*100:3.2f}% pixels selected)\"), plt.xticks(\n","    []\n","), plt.yticks([])\n","plt.subplot(1, 2, 2),\n","plt.hist(img[th].ravel(), range=[0, 255], bins=256),\n","plt.hist(img[np.invert(th)].ravel(), range=[0, 255], bins=256)\n","plt.show()\n","# return fig\n"]},{"cell_type":"markdown","metadata":{},"source":["### Exercise 1 üìù: <a name=\"Exercise_1\" id=\"Exercise_1\">  </a> Otsu under the hood \n","\n","The Otsu algorithm is based on the following idea: <br>\n","Given a grayscale image $I$ and a threshold $q$, we can compute the **weighted between-class variance** $B(q)$ as follows:\n","\n","$$\n","B(q) = c_{w} \\cdot \\sigma^2_{w}(q) + c_{b} \\cdot \\sigma^2_{b}(q)\n","$$\n","\n","where $\\sigma^2_{w}(q)$ is the variance of the **foreground** and $\\sigma^2_{b}(q)$ is the variance of the **background** and $c_{w}$ and $c_{b}$ are the number of pixels in the **foreground** and **background**, respectively.\n","\n","The **foreground** is defined as all pixels with a value greater than $q$ and the **background** as all pixels with a value less than and equal $q$. <br>\n","\n","The Otsu algorithm seeks to find the threshold $q$ that minimizes the **weighted between-class variance** $B(q)$.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img = data.coins()\n","#img = cv2.imread(\"cat.jpg\", 0)\n","#img = cv2.imread(\"gogh.jpg\", 0)\n","\n","# OpenCV's adaptive thresholding for reference\n","ref, _ = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","\n","# calculate the global otsu threshold\n","def my_otsu(img):\n","    fn_min = np.inf\n","    thresh = -1\n","\n","    for q in range (256):\n","\n","        # apply threshold\n","        th = img > q\n","\n","        # Todo: find the threshold that minimizes B(q)\n","\n","    return thresh\n","\n","print( f'Our Otsu threshold {my_otsu(img)} vs OpenCV\\'s {ref}')"]},{"cell_type":"markdown","metadata":{},"source":[" ## Local Thresholding\n","\n"," Let's now look at a local thresholding approach.\n"," In comparison to the global thresholding, the local thresholding is applied to small regions of the image.\n"," The region size is defined by the $w$ parameter."]},{"cell_type":"markdown","metadata":{},"source":["### Exercise 2 üìù: <a name=\"Exercise_2\" id=\"Exercise_2\">  </a> Local Thresholding\n","\n","Try to come up with a threshold, window and blur that separates the coins from the background. <br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def adaptive_threshold(w=11, c=2, blur=0):\n","    img = data.coins()\n","\n","    if blur > 0:\n","        img = cv2.GaussianBlur(img, None, blur)\n","\n","    th = cv2.adaptiveThreshold(\n","        img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, w, c\n","    )\n","\n","    fig = plt.figure(figsize=(15, 7), facecolor=\"white\")\n","    titles = [\n","        \"Original Image\" if blur == 0 else f\"Blurred Image\",\n","        \"Adaptive Mean Thresholding\",\n","    ]\n","    images = [img, th]\n","    for i in range(len(images)):\n","        plt.subplot(1, 2, i + 1), plt.imshow(images[i], \"gray\")\n","        plt.title(titles[i])\n","        plt.xticks([]), plt.yticks([])\n","    plt.show()\n","\n","\n","interact(\n","    adaptive_threshold,\n","    w=IntSlider(min=3, max=255, step=2, value=51),\n","    c=IntSlider(min=-50, max=50, step=1, value=2),\n","    blur=FloatSlider(min=0, max=5, step=0.1, value=0),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Another example: The Sudoko image\n","\n","Let's now look at another hard example: the Sudoko image (from the slides)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","_img = cv2.imread('sudoku.png',0)\n","img = cv2.medianBlur(_img.copy(),7).copy()\n","ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n","th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n","            cv2.THRESH_BINARY,11,2)\n","titles = ['Original Image', 'Global Thresholding ($q$ = 127)',\n","            'Adaptive Mean Thresholding']\n","images = [_img, th1, th2]\n","plt.figure(figsize=(15, 15), facecolor=\"white\")\n","for i in range(len(images)):\n","    plt.subplot(1,len(images),i+1),\n","    plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Image Regions"]},{"cell_type":"markdown","metadata":{},"source":["Let's first reuse the coins image from above. \n","And let's look at the image regions of it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# good settings for 'coins'\n","w,c,blur = 115, -22, 3\n","\n","img = data.coins()\n","img = cv2.GaussianBlur(img, None, blur)\n","\n","th = cv2.adaptiveThreshold(\n","    img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, w, c\n",")\n","binary = th > 0 \n","plt.imshow(binary, cmap=\"gray\", vmin=0, vmax=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Labels and Simple Region Properties\n","\n","Let's now look at the labels and simple region properties of the image regions, such as the area, the centroid, the bounding box, etc."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# image regions\n","\n","import cv2\n","\n","# get binary regions of binary image and compute their properties (area, BBs, centroid)\n","retval, labels, stats, centroids = cv2.connectedComponentsWithStats(binary.astype(np.uint8))\n","print( f\"Found {len(np.unique(labels))-1} (connected) regions\")\n","\n","# compute the contour perimeter of each region\n","perimeters = np.zeros_like(stats[:,4])\n","for i in range(1, len(np.unique(labels))):\n","    perimeters[i] = cv2.arcLength(cv2.findContours((labels==i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0], True)\n","\n","plt.figure(figsize=(15, 7))\n","plt.imshow(labels, cmap=\"jet\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# for each label (except the background) plot the bounding box and centroid\n","\n","img = data.coins()\n","plt.figure(figsize=(15, 7))\n","plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n","\n","for i in range(1, len(stats)):\n","    x, y, w, h, area = stats[i]\n","    # plot the BB as rectangle\n","    plt.plot([x, x + w, x + w, x, x], [y, y, y + h, y + h, y], \"go-\")\n","    plt.plot(centroids[i, 0], centroids[i, 1], \"b+\")\n","    plt.text( x, y, f\"#: {i} \\nP: {perimeters[i]} \\nA: {area}\", color=\"black\", fontsize=10, verticalalignment=\"top\", horizontalalignment=\"left\")\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Moments of Binary Image Regions\n","\n","Let's now look at the moments of one image region. \n","We will also use OpenCV to compute Hu's moments."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["region_id = 3\n","\n","# First compute the moments\n","# regular moments (m_ij)\n","# central moments (mu_ij)\n","# normalized moments (nu_ij)\n","moments = cv2.moments((labels==region_id).astype(np.uint8), True)\n","print(moments)\n","\n","\n","# compute the Hu moments\n","hu_moments = cv2.HuMoments(moments)\n","print(hu_moments.T)"]},{"cell_type":"markdown","metadata":{},"source":["# Binary Image Regions: 5 standard shapes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a helper function to compute multiple region properties\n","def compute_properties(img, hu_log=True):\n","    \"\"\"Compute properties of a binary image.\n","    Args:\n","        img (np.array): binary image\n","        hu_log (bool): if True, compute the log of the Hu moments\n","    Returns:\n","        dict: dictionary with properties area, perimeter, circularity, and hu moments (hu_0, hu_1, ... hu_6)\n","    \"\"\"\n","    # get binary regions of binary image and compute their properties (area, BBs, centroid)\n","    retval, labels, stats, centroids = cv2.connectedComponentsWithStats(img)\n","    assert( len(stats) == 2 ) # foreground (1) and background (0)\n","    # compute the contour perimeter \n","    perimeter = cv2.arcLength(cv2.findContours((labels==1).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0][0], True)\n","    circularity = 4.0*np.pi*stats[1,4]/ (.95*perimeter)**2\n","\n","    simple_props = {'area': stats[1,4], 'perimeter': perimeter, 'circularity': circularity}\n","\n","    # compute Hu moments \n","    hu_moments = cv2.HuMoments(cv2.moments((labels==1).astype(np.uint8))).flatten()\n","    if hu_log:\n","        hu_moments = np.sign(hu_moments) * np.log(np.abs(hu_moments)) # log is only defined for positive values, thus use abs\n","    hu_props = {'hu_'+str(i): hu_moments[i] for i in range(len(hu_moments))}\n","\n","    return dict( **simple_props, **hu_props )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load the shapes image and binarize it\n","img = cv2.imread(\"shapes.png\", cv2.IMREAD_GRAYSCALE)\n","#img = cv2.flip(cv2.flip(img, 1), 0) # flip image\n","#img = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST) # resize\n","img = (img>0).astype(np.uint8)\n","\n","# get binary regions of binary image and compute their properties (area, BBs, centroid)\n","retval, labels, stats, centroids = cv2.connectedComponentsWithStats(img)\n","\n","plt.figure(figsize=(15, 7), facecolor=\"white\")\n","plt.imshow(labels, cmap=\"tab10\", vmin=0, vmax=len(stats))\n","# turn off the axis\n","plt.axis(\"off\")\n","\n","for i in range(1, len(stats)):\n","    x, y, w, h, area = stats[i]\n","    # plot the BB as rectangle\n","    plt.plot([x, x + w, x + w, x, x], [y, y, y + h, y + h, y], \"wo-\")\n","    plt.plot(centroids[i, 0], centroids[i, 1], \"k+\")\n","    plt.text( centroids[i, 0], y+h+10, f\"#: {i}\", color=\"black\", fontsize=12,\n","        verticalalignment=\"top\", horizontalalignment=\"center\", # turn on latex rendering \n","    )\n","\n","\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["props = []\n","for i in range(1, len(stats)):\n","    props.append( compute_properties((labels==i).astype(np.uint8)) )\n","\n","# show as pandas table\n","df_shapes = pd.DataFrame(props, index=range(1, len(stats)))\n","df_shapes"]},{"cell_type":"markdown","metadata":{},"source":["# Compare/Match Shapes\n","\n","Let's now look at the shape descriptions of our 5 standard shapes and how we can match them with our coins image.\n","First lets look at the shape descriptions of our coins."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# good settings for 'coins'\n","w,c,blur = 115, -22, 3\n","\n","img = data.coins()\n","img = cv2.GaussianBlur(img, None, blur)\n","\n","th = cv2.adaptiveThreshold(\n","    img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, w, c\n",")\n","binary = th > 0 \n","\n","# get binary regions of binary image and compute their properties (area, BBs, centroid)\n","retval, labels, stats, centroids = cv2.connectedComponentsWithStats(binary.astype(np.uint8))\n","\n","coin_props = []\n","for i in range(1, len(stats)):\n","    coin_props.append( compute_properties((labels==i).astype(np.uint8)) )\n","\n","# show as pandas table\n","df_coins = pd.DataFrame(coin_props)   \n","df_coins"]},{"cell_type":"markdown","metadata":{},"source":["## Let's visualize the shape descriptions (in 2D)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot the coins and the shapes on a 2D plot\n","\n","x_axis = \"hu_0\"\n","y_axis = \"hu_1\"\n","\n","\n","plt.figure(figsize=(15, 7))\n","# set the axis labels\n","plt.xlabel(x_axis)\n","plt.ylabel(y_axis)\n","\n","# plot the coins in blue\n","plt.scatter(df_coins[x_axis], df_coins[y_axis], c=\"b\", label=\"coins\")\n","\n","# plot the shapes in red\n","plt.scatter(df_shapes[x_axis], df_shapes[y_axis], c=\"r\", label=\"shapes\")\n","# put the region number as label\n","for i in df_shapes.index:\n","    plt.text(df_shapes[x_axis][i], df_shapes[y_axis][i], f\"#{i}\", color=\"black\", fontsize=12, verticalalignment=\"bottom\", horizontalalignment=\"center\")\n","\n","plt.legend()\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0a05e4fa746b81761c76a645b508c0f51cdd970f4b4b50ae36c6a73f9a174174"}}},"nbformat":4,"nbformat_minor":2}
